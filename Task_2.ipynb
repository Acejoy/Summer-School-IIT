{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import imutils\n",
    "import mahotas as mt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skimage.feature import greycomatrix,greycoprops,hog\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glcm features\n",
    "\n",
    "def extract_glcm_features(image_patch):\n",
    "    \n",
    "    #feature extraction using GLCM\n",
    "    \n",
    "    grey_patch=cv2.cvtColor(image_patch,cv2.COLOR_BGR2GRAY)\n",
    "    glcm_mat=greycomatrix(grey_patch,[1],[0,np.pi/4,np.pi,0.75*np.pi],levels=256,symmetric=True,normed=True)\n",
    "    #different features\n",
    "    contrast=np.mean(greycoprops(glcm_mat,'contrast'))\n",
    "        \n",
    "    dissimilar=np.mean(greycoprops(glcm_mat,'dissimilarity'))\n",
    "        \n",
    "    homogeneity=np.mean(greycoprops(glcm_mat,'homogeneity'))\n",
    "        \n",
    "    energy=np.mean(greycoprops(glcm_mat,'energy'))\n",
    "        \n",
    "    asm=np.mean(greycoprops(glcm_mat,'ASM'))\n",
    "        \n",
    "    correlation=np.mean(greycoprops(glcm_mat,'correlation'))\n",
    "        \n",
    "    feature_vect=[correlation,dissimilar,homogeneity,energy,asm,correlation]\n",
    "    \n",
    "    \n",
    "    return feature_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the train dataset along with labels\n",
    "\n",
    "gt_folder_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Ground Truth'\n",
    "\n",
    "orig_folder_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Original Image'\n",
    "\n",
    "#segments = ['Bicycle', 'Car', 'Human']\n",
    "segments = ['Car', 'Human']\n",
    "\n",
    "#lists of data\n",
    "train_label = []\n",
    "glcm_train_data = []\n",
    "hog_train_data = []\n",
    "brisk_train_data = []\n",
    "\n",
    "humoments_train_data = []\n",
    "haralick_train_data = []\n",
    "#encoding the label names into numbers\n",
    "#human is 0\n",
    "#car is 1\n",
    "#bicycle is 2\n",
    "\n",
    "encoded ={'human':0, 'car':1, 'bicycle':1}\n",
    "\n",
    "\n",
    "#describing the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "\n",
    "#initialising the brisk descriptor\n",
    "brisk = cv2.BRISK_create()\n",
    "\n",
    "\n",
    "for segment in segments:\n",
    "    \n",
    "    image_folder = os.path.join(orig_folder_path,segment)\n",
    "    gt_image_folder = os.path.join(gt_folder_path,segment)\n",
    "    \n",
    "    \n",
    "    list_orig = os.listdir(image_folder)\n",
    "    list_gt = os.listdir(gt_image_folder)\n",
    "    \n",
    "    for orig_name,gt_name in zip(list_orig,list_gt):\n",
    "        \n",
    "        orig_image = cv2.imread(os.path.join(image_folder,orig_name),1)\n",
    "        gt_image = cv2.imread(os.path.join(gt_image_folder,gt_name),0)\n",
    "        \n",
    "        if segment == 'Bicycle':\n",
    "            gt_image = np.invert(gt_image)\n",
    "            train_label.append(1)\n",
    "        \n",
    "        if segment == 'Human':\n",
    "            train_label.append(0)\n",
    "            \n",
    "        if segment == 'Car':\n",
    "            train_label.append(1)\n",
    "            \n",
    "        #edged = imutils.auto_canny(gt_image)    \n",
    "        contours,hierarchies = cv2.findContours(gt_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        max_cnt=max(contours,key=cv2.contourArea)\n",
    "            \n",
    "        max_rect=cv2.boundingRect(max_cnt)\n",
    "        x,y,w,h = max_rect\n",
    "        \n",
    "        '''\n",
    "        cv2.rectangle(orig_image,(x,y),(x+w,y+h),(0,0,255),1)\n",
    "        \n",
    "        cv2.imshow(orig_name,orig_image)\n",
    "        k=cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if k == ord('q'):\n",
    "            cv2.destroyWindow(orig_name)\n",
    "            break\n",
    "        else:\n",
    "            cv2.destroyWindow(orig_name)\n",
    "         \n",
    "        #cv2.destroyWindow(orig_name)\n",
    "        '''\n",
    "        \n",
    "        image_patch=orig_image[y:y+h, x:x+w ]\n",
    "        #resizing to 64 X 128\n",
    "        #print(orig_name,x,y,w,h)\n",
    "        \n",
    "        resized_patch = cv2.resize(image_patch,(64,128))\n",
    "        \n",
    "        edged_patch = cv2.Canny(resized_patch,200,230)\n",
    "        \n",
    "        '''\n",
    "        cv2.imshow('edge',edged_patch)\n",
    "        cv2.imshow('orig',image_patch)\n",
    "        k=cv2.waitKey(0) & 0xFF\n",
    "        \n",
    "        if k == ord('q'):\n",
    "            cv2.destroyWindow(orig_name)\n",
    "            cv2.destroyWindow('edge')\n",
    "            cv2.destroyWindow('orig')\n",
    "            break\n",
    "        else:\n",
    "            cv2.destroyWindow(orig_name)\n",
    "            cv2.destroyWindow('edge')\n",
    "            cv2.destroyWindow('orig')\n",
    "        '''\n",
    "        \n",
    "        #extracting features\n",
    "        #extracting the glcm features\n",
    "        \n",
    "        glcm_train_data.append(np.asarray(extract_glcm_features(resized_patch)))\n",
    "        \n",
    "        #extract hog features\n",
    "        hog_fetures = hog.compute(cv2.cvtColor(resized_patch,cv2.COLOR_BGR2GRAY))\n",
    "        hog_train_data.append(hog_fetures.reshape(3780))\n",
    "        \n",
    "        humoments_train_data.append(cv2.HuMoments(cv2.moments(gt_image[y:y+h,x:x+w])))\n",
    "        \n",
    "        haralick_train_data.append(mt.features.haralick(resized_patch))\n",
    "        '''\n",
    "        #extract brisk features\n",
    "        keypoint , features = brisk.detectAndCompute(resized_patch,None)\n",
    "        brisk_train_data.append(features.flatten())\n",
    "        '''\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomise the datasets: labels and data\n",
    "randomise = np.arange(len(hog_train_data))\n",
    "np.random.shuffle(randomise)\n",
    "\n",
    "hog_train_data = np.asarray(hog_train_data)\n",
    "hog_train_data = hog_train_data[randomise]\n",
    "\n",
    "glcm_train_data = np.asarray(glcm_train_data)\n",
    "glcm_train_data = glcm_train_data[randomise]\n",
    "\n",
    "'''\n",
    "humoments_train_data = np.asarray(humoments_train_data)\n",
    "humoments_train_data = humoments_train_data.reshape(-1,7)\n",
    "humoments_train_data = humoments_train_data[randomise]\n",
    "\n",
    "\n",
    "haralick_train_data = np.asarray(haralick_train_data)\n",
    "haralick_train_data = haralick_train_data.reshape(248,-1)\n",
    "haralick_train_data = haralick_train_data[randomise]\n",
    "\n",
    "'''\n",
    "train_label = np.asarray(train_label)\n",
    "train_label = train_label[randomise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n",
      "(1, 169)\n"
     ]
    }
   ],
   "source": [
    "linsvm=SVC(kernel='linear',gamma='auto')\n",
    "polysvm = SVC(kernel = 'poly',gamma='auto')\n",
    "rbfsvm = SVC(kernel='rbf',gamma='auto')\n",
    "\n",
    "'''\n",
    "linsvm.fit(haralick_train_data,train_label)\n",
    "polysvm.fit(haralick_train_data, train_label)\n",
    "rbfsvm.fit(haralick_train_data,train_label)\n",
    "print()\n",
    "\n",
    "\n",
    "linsvm.fit(humoments_train_data,train_label)\n",
    "polysvm.fit(humoments_train_data, train_label)\n",
    "rbfsvm.fit(humoments_train_data,train_label)\n",
    "print()\n",
    "\n",
    "linsvm.fit(hog_train_data,train_label)\n",
    "polysvm.fit(hog_train_data, train_label)\n",
    "rbfsvm.fit(hog_train_data,train_label)\n",
    "\n",
    "'''\n",
    "linsvm.fit(glcm_train_data,train_label)\n",
    "polysvm.fit(glcm_train_data, train_label)\n",
    "rbfsvm.fit(glcm_train_data,train_label)\n",
    "\n",
    "\n",
    "orig_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Testing01\\Original'\n",
    "gt_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Testing01\\GT'\n",
    "\n",
    "#gt_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Ground Truth\\Car'\n",
    "#orig_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Original Image\\Car'\n",
    "\n",
    "list_orig_test = os.listdir(orig_test_path)\n",
    "list_gt_test = os.listdir(gt_test_path)\n",
    "\n",
    "#print(list_orig_test)\n",
    "#print(list_gt_test)\n",
    "bbox_encoding = {0:(0,0,255), 1:(0,255,0), 2:(255,0,0)}\n",
    "\n",
    "hog=cv2.HOGDescriptor()\n",
    "\n",
    "for orig_test_image_name,gt_test_image_name in zip(list_orig_test,list_gt_test):\n",
    "    \n",
    "    orig_test_image = cv2.imread(os.path.join(orig_test_path,orig_test_image_name),1)\n",
    "    #print(os.path.join(orig_test_path,orig_test_image_name))\n",
    "    \n",
    "    gt_test_image = cv2.imread(os.path.join(gt_test_path,gt_test_image_name),0)\n",
    "    #gt_test_image = np.invert(gt_test_image)\n",
    "    #print(os.path.join(gt_test_path,gt_test_image_name))\n",
    "    \n",
    "    \n",
    "    contours,hierarchies = cv2.findContours(gt_test_image , cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "    \n",
    "    patches = []\n",
    "    \n",
    "    for rect in rects:\n",
    "        x,y,w,h = rect\n",
    "        patch = orig_test_image[y:y+h,x:x+w]\n",
    "        resized_patch = cv2.resize(patch,(64,128))\n",
    "        \n",
    "        glcm_feature = np.asarray(extract_glcm_features(resized_patch))\n",
    "        #print(glcm_feature.shape)\n",
    "        hog_features=hog.compute(resized_patch).reshape(3780)\n",
    "        \n",
    "        humoment_data = cv2.HuMoments(cv2.moments(gt_test_image[y:y+h,x:x+w]))\n",
    "        humoment_data = humoment_data.reshape(-1,7)\n",
    "        \n",
    "        haralick_feature = mt.features.haralick(resized_patch)\n",
    "        haralick_feature = haralick_feature.reshape(1,-1)\n",
    "        print(haralick_feature.shape)\n",
    "        \n",
    "        y_pred = rbfsvm.predict([glcm_feature])\n",
    "        \n",
    "        #print(y_pred[0])\n",
    "        \n",
    "        cv2.rectangle(orig_test_image, (x,y),(x+w,y+h),bbox_encoding[y_pred[0]],1)\n",
    "    cv2.imshow(orig_test_image_name,orig_test_image)\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "    if k== ord('q'):\n",
    "        cv2.destroyWindow(orig_test_image_name)\n",
    "        break\n",
    "    else :\n",
    "        cv2.destroyWindow(orig_test_image_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linsvm=SVC(kernel='linear',gamma='auto')\n",
    "polysvm = SVC(kernel = 'poly',gamma='auto')\n",
    "rbfsvm = SVC(kernel='rbf',gamma='auto')\n",
    "\n",
    "\n",
    "linsvm.fit(hog_train_data,train_label)\n",
    "polysvm.fit(hog_train_data, train_label)\n",
    "rbfsvm.fit(hog_train_data,train_label)\n",
    "\n",
    "\n",
    "\n",
    "#testing scene\n",
    "\n",
    "frameset_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\ethz\\images\\pedxing-seq1'\n",
    "\n",
    "list_frames = os.listdir(frameset_test_path)\n",
    "\n",
    "list_frames.remove('maps')\n",
    "\n",
    "fg_extractor = cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "bbox_encoding = { 0:(0,0,255), 1:(0,255,0) }\n",
    "\n",
    "for frame_name in list_frames:\n",
    "    \n",
    "    frame_path = os.path.join(frameset_test_path, frame_name)\n",
    "    \n",
    "    frame =cv2.imread(frame_path, 1)\n",
    "    frame = cv2.resize(frame,(200,150))\n",
    "    grey_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    fg_mask = fg_extractor.apply(grey_frame)\n",
    "    \n",
    "    fg_mask = cv2.GaussianBlur(fg_mask, (5,5), 0)\n",
    "    \n",
    "    contours,hierarchies = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    \n",
    "    for cnt in contours:\n",
    "        \n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        if w*h  > 100:\n",
    "            \n",
    "            patch = frame[y:y+h,x:x+w]\n",
    "            resized_patch = cv2.resize(patch,(64,128))\n",
    "        \n",
    "            glcm_feature = np.asarray(extract_glcm_features(resized_patch))\n",
    "            #print(glcm_feature.shape)\n",
    "            hog_features=hog.compute(resized_patch).reshape(3780)\n",
    "        \n",
    "            y_pred = rbfsvm.predict([hog_features])\n",
    "        \n",
    "            #print(y_pred[0])\n",
    "        \n",
    "            cv2.rectangle(frame, (x,y),(x+w,y+h),bbox_encoding[y_pred[0]],1)\n",
    "    cv2.imshow('mask',fg_mask)\n",
    "    cv2.imshow('grey_image', cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "    cv2.imshow('frame_name',frame)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    time.sleep(0.0003333)\n",
    "    if k== ord('q'):        \n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sknn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a4faf5ed1d46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msknn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sknn'"
     ]
    }
   ],
   "source": [
    "import sknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
