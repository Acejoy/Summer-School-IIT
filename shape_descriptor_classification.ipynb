{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import mahotas as mt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the train dataset along with labels\n",
    "\n",
    "gt_folder_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Ground Truth'\n",
    "\n",
    "orig_folder_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Original Image'\n",
    "\n",
    "segments = ['Bicycle', 'Car', 'Human']\n",
    "\n",
    "\n",
    "#lists of data\n",
    "train_label = []\n",
    "hog_train_data = []\n",
    "humoments_train_data = []\n",
    "\n",
    "\n",
    "#encoding the label names into numbers\n",
    "#human is 0\n",
    "#car is 1\n",
    "#bicycle is 2\n",
    "\n",
    "encoded ={'human':0, 'car':1, 'bicycle':2}\n",
    "\n",
    "\n",
    "#describing the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "\n",
    "#initialising the brisk descriptor\n",
    "brisk = cv2.BRISK_create()\n",
    "\n",
    "\n",
    "for segment in segments:\n",
    "    \n",
    "    image_folder = os.path.join(orig_folder_path,segment)\n",
    "    gt_image_folder = os.path.join(gt_folder_path,segment)\n",
    "    \n",
    "    \n",
    "    list_orig = os.listdir(image_folder)\n",
    "    list_gt = os.listdir(gt_image_folder)\n",
    "    \n",
    "    for orig_name,gt_name in zip(list_orig,list_gt):\n",
    "        \n",
    "        orig_image = cv2.imread(os.path.join(image_folder,orig_name),1)\n",
    "        gt_image = cv2.imread(os.path.join(gt_image_folder,gt_name),0)\n",
    "        \n",
    "        if segment == 'Bicycle':\n",
    "            gt_image = np.invert(gt_image)\n",
    "            train_label.append(2)\n",
    "        \n",
    "        if segment == 'Human':\n",
    "            train_label.append(0)\n",
    "            \n",
    "        if segment == 'Car':\n",
    "            train_label.append(1)\n",
    "        grey_scaled_image = cv2.cvtColor(orig_image,cv2.COLOR_BGR2GRAY)    \n",
    "        edges = cv2.Canny(gt_image,230,250)\n",
    "        \n",
    "        contours,hierarchies = cv2.findContours(edges,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        max_cnt = max(contours,key=cv2.contourArea)\n",
    "        \n",
    "        max_rect = cv2.boundingRect(max_cnt)\n",
    "        #cv2.drawContours(orig_image,contours,-1,(0,0,255),2)\n",
    "        \n",
    "        x,y,w,h = max_rect\n",
    "        \n",
    "        '''\n",
    "        cv2.rectangle(orig_image,(x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.imshow(orig_name,orig_image)\n",
    "        cv2.imshow(gt_name,edges)\n",
    "        k = cv2.waitKey(0) & 0xFF\n",
    "        if k == ord('q'):\n",
    "            cv2.destroyWindow(orig_name)\n",
    "            cv2.destroyWindow(gt_name)\n",
    "            break\n",
    "        else:\n",
    "            cv2.destroyWindow(orig_name)\n",
    "            cv2.destroyWindow(gt_name)\n",
    "        '''\n",
    "        \n",
    "        if segment == 'Bicycle':\n",
    "            resized_patch = cv2.resize(edges,(64,128))\n",
    "        else:\n",
    "            image_patch = edges[y:y+h,x:x+w]\n",
    "            resized_patch = cv2.resize(edges,(64,128))\n",
    "                \n",
    "        hog_feature = hog.compute(resized_patch)\n",
    "        hog_train_data.append(hog_feature.reshape(3780))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomise the datasets: labels and data\n",
    "randomise = np.arange(len(hog_train_data))\n",
    "np.random.shuffle(randomise)\n",
    "\n",
    "hog_train_data = np.asarray(hog_train_data)\n",
    "hog_train_data = hog_train_data[randomise]\n",
    "\n",
    "train_label = np.asarray(train_label)\n",
    "train_label = train_label[randomise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "linsvm=SVC(kernel='linear',gamma='auto')\n",
    "polysvm = SVC(kernel = 'poly',gamma='auto')\n",
    "rbfsvm = SVC(kernel='rbf',gamma='auto')\n",
    "\n",
    "linsvm.fit(hog_train_data,train_label)\n",
    "polysvm.fit(hog_train_data, train_label)\n",
    "rbfsvm.fit(hog_train_data,train_label)\n",
    "\n",
    "orig_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Testing01\\Original'\n",
    "gt_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Testing01\\GT'\n",
    "\n",
    "#gt_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Ground Truth\\Car'\n",
    "#orig_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Original Image\\Car'\n",
    "\n",
    "list_orig_test = os.listdir(orig_test_path)\n",
    "list_gt_test = os.listdir(gt_test_path)\n",
    "\n",
    "#print(list_orig_test)\n",
    "#print(list_gt_test)\n",
    "bbox_encoding = {0:(0,0,255), 1:(0,255,0), 2:(255,0,0)}\n",
    "\n",
    "hog=cv2.HOGDescriptor()\n",
    "\n",
    "for orig_test_image_name,gt_test_image_name in zip(list_orig_test,list_gt_test):\n",
    "    \n",
    "    orig_test_image = cv2.imread(os.path.join(orig_test_path,orig_test_image_name),1)\n",
    "    #print(os.path.join(orig_test_path,orig_test_image_name))\n",
    "    \n",
    "    gt_test_image = cv2.imread(os.path.join(gt_test_path,gt_test_image_name),0)\n",
    "    #gt_test_image = np.invert(gt_test_image)\n",
    "    #print(os.path.join(gt_test_path,gt_test_image_name))\n",
    "    \n",
    "    \n",
    "    contours,hierarchies = cv2.findContours(gt_test_image , cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "    \n",
    "    patches = []\n",
    "    \n",
    "    for rect in rects:\n",
    "        x,y,w,h = rect\n",
    "        patch = orig_test_image[y:y+h,x:x+w]\n",
    "        resized_patch = cv2.resize(patch,(64,128))\n",
    "        \n",
    "        hog_features=hog.compute(resized_patch).reshape(3780)\n",
    "        \n",
    "        y_pred = polysvm.predict([hog_features])\n",
    "        \n",
    "        #print(y_pred[0])\n",
    "        \n",
    "        cv2.rectangle(orig_test_image, (x,y),(x+w,y+h),bbox_encoding[y_pred[0]],1)\n",
    "    cv2.imshow(orig_test_image_name,orig_test_image)\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "    if k== ord('q'):\n",
    "        cv2.destroyWindow(orig_test_image_name)\n",
    "        break\n",
    "    else :\n",
    "        cv2.destroyWindow(orig_test_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using the sklearn hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mahotas\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "from skimage import feature\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_folder_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Ground Truth'\n",
    "\n",
    "orig_folder_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Original Image'\n",
    "\n",
    "segments = ['Bicycle', 'Car', 'Human']\n",
    "\n",
    "\n",
    "#lists of data\n",
    "train_label = []\n",
    "skimage_hog_train_data = []\n",
    "\n",
    "\n",
    "#encoding the label names into numbers\n",
    "#human is 0\n",
    "#car is 1\n",
    "#bicycle is 2\n",
    "\n",
    "encoded ={'human':0, 'car':1, 'bicycle':2}\n",
    "\n",
    "\n",
    "#describing the HOG descriptor\n",
    "hog = cv2.HOGDescriptor()\n",
    "\n",
    "#initialising the brisk descriptor\n",
    "brisk = cv2.BRISK_create()\n",
    "\n",
    "\n",
    "for segment in segments:\n",
    "    \n",
    "    image_folder = os.path.join(orig_folder_path,segment)\n",
    "    gt_image_folder = os.path.join(gt_folder_path,segment)\n",
    "    \n",
    "    \n",
    "    list_orig = os.listdir(image_folder)\n",
    "    list_gt = os.listdir(gt_image_folder)\n",
    "    \n",
    "    for orig_name,gt_name in zip(list_orig,list_gt):\n",
    "        \n",
    "        orig_image = cv2.imread(os.path.join(image_folder,orig_name),1)\n",
    "        gt_image = cv2.imread(os.path.join(gt_image_folder,gt_name),0)\n",
    "        \n",
    "        if segment == 'Bicycle':\n",
    "            gt_image = np.invert(gt_image)\n",
    "            train_label.append(2)\n",
    "        \n",
    "        if segment == 'Human':\n",
    "            train_label.append(0)\n",
    "            \n",
    "        if segment == 'Car':\n",
    "            train_label.append(1)\n",
    "        \n",
    "        grey_scaled_image = cv2.cvtColor(orig_image,cv2.COLOR_BGR2GRAY)    \n",
    "        \n",
    "        edges = cv2.Canny(gt_image,230,250)\n",
    "        \n",
    "        contours,hierarchies = cv2.findContours(edges,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        max_cnt = max(contours,key=cv2.contourArea)\n",
    "        \n",
    "        max_rect = cv2.boundingRect(max_cnt)\n",
    "        #cv2.drawContours(orig_image,contours,-1,(0,0,255),2)\n",
    "        \n",
    "        x,y,w,h = max_rect\n",
    "        \n",
    "        image_patch = grey_scaled_image[y:y+h,x:x+w]\n",
    "        resized_patch = cv2.resize(image_patch,(64,128))\n",
    "        \n",
    "        H,h_image = feature.hog(resized_patch, orientations=9, pixels_per_cell=(10,10),\n",
    "                       cells_per_block=(2,2), transform_sqrt=True, block_norm=\"L1\",visualize = True)\n",
    "\n",
    "        h_image = exposure.rescale_intensity(h_image, out_range=(0,255))\n",
    "        h_image = h_image.astype('uint8')\n",
    "        \n",
    "        cv2.imshow('hog image',h_image)\n",
    "        cv2.imshow('gt',gt_image)\n",
    "        k=cv2.waitKey(0) & 0xFF\n",
    "        if k==ord('q'):\n",
    "            cv2.destroyWindow('hog_image')\n",
    "            cv2.destroyWindow('gt')\n",
    "            break\n",
    "        else:\n",
    "            cv2.destroyWindow('hog_image')\n",
    "            cv2.destroyWindow('gt')\n",
    "        \n",
    "        skimage_hog_train_data.append(H)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(skimage_hog_train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomise the datasets: labels and data\n",
    "randomise = np.arange(len(skimage_hog_train_data))\n",
    "np.random.shuffle(randomise)\n",
    "\n",
    "skimage_hog_train_data = np.asarray(skimage_hog_train_data)\n",
    "skimage_hog_train_data = skimage_hog_train_data[randomise]\n",
    "\n",
    "train_label = np.asarray(train_label)\n",
    "train_label = train_label[randomise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "linsvm=SVC(kernel='linear',gamma='auto')\n",
    "polysvm = SVC(kernel = 'poly',gamma='auto')\n",
    "rbfsvm = SVC(kernel='rbf',gamma='auto')\n",
    "\n",
    "linsvm.fit(skimage_hog_train_data,train_label)\n",
    "polysvm.fit(skimage_hog_train_data, train_label)\n",
    "rbfsvm.fit(skimage_hog_train_data,train_label)\n",
    "\n",
    "orig_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Testing01\\Original'\n",
    "gt_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Testing01\\GT'\n",
    "\n",
    "#gt_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Ground Truth\\Car'\n",
    "#orig_test_path = r'C:\\Users\\Legion\\Desktop\\Internship_IIT\\Training & esting Dataset\\Datasets\\Training01\\Original Image\\Car'\n",
    "\n",
    "list_orig_test = os.listdir(orig_test_path)\n",
    "list_gt_test = os.listdir(gt_test_path)\n",
    "\n",
    "#print(list_orig_test)\n",
    "#print(list_gt_test)\n",
    "bbox_encoding = {0:(0,0,255), 1:(0,255,0), 2:(255,0,0)}\n",
    "\n",
    "hog=cv2.HOGDescriptor()\n",
    "\n",
    "for orig_test_image_name,gt_test_image_name in zip(list_orig_test,list_gt_test):\n",
    "    \n",
    "    orig_test_image = cv2.imread(os.path.join(orig_test_path,orig_test_image_name),1)\n",
    "    #print(os.path.join(orig_test_path,orig_test_image_name))\n",
    "    \n",
    "    gt_test_image = cv2.imread(os.path.join(gt_test_path,gt_test_image_name),0)\n",
    "    #gt_test_image = np.invert(gt_test_image)\n",
    "    #print(os.path.join(gt_test_path,gt_test_image_name))\n",
    "    \n",
    "    \n",
    "    \n",
    "    contours,hierarchies = cv2.findContours(gt_test_image , cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "    \n",
    "        \n",
    "    for rect in rects:\n",
    "        x,y,w,h = rect\n",
    "        patch = orig_test_image[y:y+h,x:x+w]\n",
    "        resized_patch = cv2.resize(patch,(64,128))\n",
    "        \n",
    "        hog_features,h_image =feature.hog(resized_patch, orientations=9, pixels_per_cell=(10, 10),\n",
    "                                 cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L1\",visualize=True)        \n",
    "        y_pred = rbfsvm.predict(hog_features.reshape(1,-1))\n",
    "        \n",
    "        print(y_pred[0])\n",
    "        \n",
    "        h_image = exposure.rescale_intensity(h_image,out_range=(0,255))\n",
    "        h_image = h_image.astype('uint8')\n",
    "        cv2.imshow('hog patch',h_image)\n",
    "        cv2.imshow('patch' ,resized_patch)\n",
    "        \n",
    "        k = cv2.waitKey(0) & 0xFF\n",
    "        if k== ord('q'):\n",
    "            cv2.destroyWindow('patch')\n",
    "            cv2.destroyWindow('hog_patch')\n",
    "            break\n",
    "        else :\n",
    "            cv2.destroyWindow('patch')\n",
    "            cv2.destroyWindow('hog_patch')\n",
    "        \n",
    "        cv2.rectangle(orig_test_image, (x,y),(x+w,y+h),bbox_encoding[y_pred[0]],1)\n",
    "    cv2.imshow(orig_test_image_name,orig_test_image)\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "    if k== ord('q'):\n",
    "        cv2.destroyWindow(orig_test_image_name)\n",
    "        break\n",
    "    else :\n",
    "        cv2.destroyWindow(orig_test_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
